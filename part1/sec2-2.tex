\documentclass[part1.tex]{subfiles}
\begin{document}

\section{Resolution in HA-based logic}
\subsection{Overview of inference in LSHA-based propositional logic}
\paragraph{Logical consequence:} A is a logical consequence of B if every interpretation 
satisfying A also satisties B. Notated: A \(\models\) B.\\
\paragraph{Inference rule:} An inference rule of the form\\
\begin{align*}
	\frac{F_1, F_2,\cdots,F_n}{G}
\end{align*}
means that with a given set of formula \(F_1,F_2,\cdots,F_n\), we can deduce a 
new formula \(G\). An inference rule is sound if it satisfies logical consequence.\\
To be useful, aside from being sound, an inference rule also should be complete, meaning\\
it deduce every formula that is a logical consequence of the original set of formulae.\\
\paragraph{Confidence value:}
In fuzzy logic, inference rules are only approximately true, so formulae derived by them must be
taken with a {\em confidence value}. A formula F with \(\alpha\) confidence is denoted by \(F_\alpha\).\\

Clauses in the initial knowledge base are given with some confidence value. The confidence of formulae
derived from them will be determined by their given confidence value. Obviously the derived formula's 
confidence must not be larger than its original formulae's.

\subsection{Resolution rule}
\paragraph{Resolution rule:} Given \(A^a \vee B^{b1}\) and \(C^c \vee B^{b2}\). If \(b1 \vee b2 
\ge W\) and \(b1 \wedge b2 < W\):
\begin{align*}
	&\frac{(A^a \vee B^{b1}, {\alpha 1}), (C^c \vee B^{b2}, {\alpha 2})} {(A^a \vee C^c, {\alpha 3})}\\
	&\text{Where: }
	\begin{cases}
	\alpha 1, \alpha 2, \alpha 3 \text{ are the confidence
        values of formulae.}\\
	A, B, C \text{ are propositional symbols}\\
	a, b1, b2, c \text{ are linguistic value}
	\end{cases}
	\\
	&\text{If } (A^a \vee B^{b1}, {\alpha 1}) \wedge (C^c \vee B^{b2}, {\alpha 2}) \text{ is 
	unsatisfiable, the result of resolution is the null clause.} 
\end{align*}
\paragraph{} Since the resolution rule only applies to
disjuntions of literals, to be able to reasoning using
resolution, we first have to transform the original formulae into
a conjuntion of disjunction of literals, or a CNF.  The procedure
to achieve this was discussed in the previous section.\\

\subsection{Resolution algorithm:} 
 To prove that a goal clause G entails the knowledge base KB, e.g \(KB \models G\), we can instead prove
that \(KB \cup \neg G\) is unsatisfiable.\\\\
\indent {\em Input: S = \(KB \cup \neg G\)}\\
\indent {\em Output: A confidence value if S in unsatisfiable,
Nothing otherwise}\\\\
\indent{\bfseries BEGIN}\\
\indent If (S contains NULL) thenn return true;\\
\indent Foreach (clause C1 in S)\\
\indent \indent Foreach (clause C2 in S)\\
\indent \indent \indent If (C1 and C2 can be resolved) C3 := resolve(C1,C2);\\
\indent \indent \indent If (C3 = NULL) return Confidence(C3);\\
\indent \indent \indent Else Reduce(C3)\\
\indent \indent \indent \indent (Add C3 to S);\\
\indent If (S does not contain NULL) then return Nothing;\\
\indent{\bfseries END}
\paragraph{} Where Confidence(C3) is the confidence value of
C3, and Reduce(C3) is C3 after it was reduced by elimination of
redundant literals. The following subsections will further
elaborate on them.

\subsection{Reducing disjunction of literals}
\paragraph{} Unlike classical propositional logic,
literals in this fuzzy propositional logic can say the same thing
(i.e. have the same symbol) but have different truth value
annotated to them which are significant in interpretation, and
eliminating arbitrary literals among them may change the clause's
semantics. Because of this, we have to consider a way to safely
reduce disjunction-of-literals without altering its semantics.
\paragraph{Theorem:} Given a symbol A, for any interpretation
I:\{A = c\}, we have:
\[
   \begin{cases}
           T_{I:\{A = c\}}(A^{a} \vee A^{b}) &=  T_{I:\{A =
           c\}}(A^{a \vee b})  \text{ if } c \ge W \\

           T_{I:\{A = c\}}(A^{a} \vee A^{b}) &=  T_{I:\{A =
           c\}}(A^{a \wedge b}) \text{ if } c < W
   \end{cases}
\]

\subsubsection{Proof:}
{\bfseries Case 1: a, b > W, c $\ge$ W}
\begin{align*}
        T_{I:\{A = c\}}(A^{a} \vee A^{b}) &= T_{I:\{A =
                 c\}}(A^{a}) \vee T_{I:\{A = c\}}(A^{b}) \\
                 &= (a \wedge c) \vee (b \wedge c) \\
                 &= (a \vee b) \wedge c \\
                 &= T_{I:\{A = c\}}(A^{a \vee b}) \\
\end{align*}

{\bfseries Case 2: a, b > W, c < W}
\begin{align*}
        T_{I:\{A = c\}}(A^{a} \vee A^{b}) 
                 &= T_{I:\{A = c\}}(A^{a}) \vee T_{I:\{A = c\}}(A^{b}) \\
                 &= (\neg{a} \vee c) \vee (\neg{b} \vee c) \\
                 &= (\neg{a} \vee \neg{b}) \vee c \\
                 &= \neg{(a \wedge b)} \vee c \\
                 &= T_{I:\{A = c\}}(A^{a \wedge b}) \\
\end{align*}

{\bfseries Case 3: a, b < W, c $\ge$ W}
\begin{align*}
        T_{I:\{A = c\}}(A^{a} \vee A^{b}) 
                 &= T_{I:\{A = c\}}(A^{a}) \vee T_{I:\{A = c\}}(A^{b}) \\
                 &= (a \vee \neg{c}) \vee (b \vee \neg{c}) \\
                 &= (a \vee b) \vee \neg{c} \\
                 &= T_{I:\{A = c\}}(A^{a \vee b}) \\
\end{align*}

{\bfseries Case 4: a, b < W, c < W}
\begin{align*}
        T_{I:\{A = c\}}(A^{a} \vee A^{b}) 
                 &= T_{I:\{A = c\}}(A^{a}) \vee T_{I:\{A = c\}}(A^{b}) \\
                 &= \neg{(a \vee c)} \vee \neg{(b \vee c)} \\
                 &= (\neg{a} \wedge \neg{c}) \vee (\neg{b} \wedge \neg{c})\\
                 &= (\neg{a} \vee \neg{b}) \wedge \neg{c}\\
                 &= \neg{(a \wedge b)} \wedge \neg{c}\\
                 &= \neg{((a \wedge b) \vee c)}\\
                 &= T_{I:\{A = c\}}(A^{a \wedge b}) \\
\end{align*}

{\bfseries Case 5: a > W, b < W, c $\ge$ W}
\begin{align*}
        T_{I:\{A = c\}}(A^{a} \vee A^{b}) 
                 &= T_{I:\{A = c\}}(A^{a}) \vee T_{I:\{A = c\}}(A^{b}) \\
                 &= (a \wedge c) \vee (b \vee \neg{c}) \\
                 &= (a \vee b \vee \neg{c}) \wedge (b \vee \neg{c} \vee c)\\
                 &= (a \vee b \vee \neg{c}) \wedge (b \vee c)\\
                 &= (a \wedge b) \vee (a \wedge c) \vee (b \wedge
                        b) \vee (b \wedge c) \vee (b \wedge \neg{c}) \vee (c \wedge
                        \neg{c})\\            
                 &= (a \wedge c) \text{\: (for $a \wedge c = max(a \wedge
                        b, a \wedge c, b \wedge
                        b = b, b \wedge c, b \wedge \neg{c}, c \wedge
                        \neg{c} = \neg{c})$)}\\        
                 &= (a \vee b) \wedge c \text{\: (for $a
                        \vee b = max(a,b) = a$)} \\
                 &= T_{I:\{A = c\}}(A^{a \vee b}) \\
\end{align*}

{\bfseries Case 6: a > W, b < W, c < W}
\begin{align*}
        T_{I:\{A = c\}}(A^{a} \vee A^{b}) 
                 &= T_{I:\{A = c\}}(A^{a}) \vee T_{I:\{A = c\}}(A^{b}) \\
                 &= (\neg{a} \vee c) \vee \neg{(b \vee c)} \\
                 &=  (\neg{a} \vee c) \vee (\neg{b} \wedge \neg{c})\\
                 &= (\neg{a} \vee \neg{b} \vee c) \wedge (\neg{a} \vee c \vee \neg{c}\\
                 &= (\neg{a} \vee \neg{b} \vee c) \wedge (\neg{a} \vee \neg{c}\\
                 &= \neg{a} \vee ((\neg{b} \vee c) \wedge \neg{c}))\\
                 &= \neg{a} \vee (\neg{b} \wedge \neg{c})\\
                 &= \neg{b} \wedge \neg{c} \text{
        \: (for $(\neg{b} \wedge \neg{c}) = max(\neg{a}, \neg{b} \wedge \neg{c})$)}\\
                 &= \neg{(b \vee c)}\\
                 &= \neg{(b \wedge a) \vee c} \text{\: (for $b = min(a,b)$)}\\
                 &= \neg{((a \wedge b) \vee c)}\\
                 &= T_{I:\{A = c\}}(A^{a \wedge b}) \\
\end{align*}
\paragraph{} From {\bfseries case 1 -> case 6}\\
$\implies$ \(
   \begin{cases}
           T_{I:\{A = c\}}(A^{a} \vee A^{b}) &=  T_{I:\{A =
           c\}}(A^{a \vee b})  \text{ if } c \ge W \\

           T_{I:\{A = c\}}(A^{a} \vee A^{b}) &=  T_{I:\{A =
           c\}}(A^{a \wedge b}) \text{ if } c < W
   \end{cases} 
   \) (q.e.d).
\paragraph{} From this theorem, it's easy to see that for any
disjunction of literals $A_{n} = A^{a1} \vee A^{a2} ... \vee A^{a_{n}}$,
I(A) = b, if b $\ge$ W then $A_{n} = a^{max(a1,..a_{n})}$, otherwise
$A_{n} = a^{min(a1,..a_{n})}$
\subsection{Confidence value in HA-based logic}
By the definition of resolution, we can see for the two clauses to be able to resolve, \(b_1\) and 
\(b_2\) must be on different side w.r.t. W, and the bigger their difference, the more reliable the 
inference. We consider 4 methods to determine the confidence value of an inference step.\\
\subsubsection{Confidence using min}
Obviously, the inference step is more certain as the smaller value of \(b_1\) and \(b_2\) is closer to 
0. In particular, the confidence value of the inferred clause is:
\begin{align*}
	{\alpha}_3 = \wedge({\alpha}_1, {\alpha}_2, \neg(b_1 \wedge b_2))
\end{align*}
\subsubsection{Confidence using max}
Conversely, the inference step is more certain as the bigger value of \(b_1\) and \(b_2\) is closer to 
1. In particular, the confidence value of the inferred clause is:
\begin{align*}
	{\alpha}_3 = \wedge({\alpha}_1, {\alpha}_2, (b_1 \vee b_2))
\end{align*}
\subsubsection{Confidence using max and min}
Each of the previous method can only express part of the confidence of the resolution. We can combine
them to get a confidence value that represent both the ``false'' and ``true'' values \(b_1\) and 
\(b_2\). In particular, the confidence value of the inferred clause is:
\begin{align*}
	{\alpha}_3 = \wedge({\alpha}_1, {\alpha}_2, (b_1 \vee b_2), \neg(b_1 \wedge b_2))
\end{align*}

\paragraph{}From here on out, we would implicitly mean the third method
(combining max and min) when talking about confidence calculating
method, unless it was said otherwise.


\subsection{Proof of Soundness}
Proof of soundness means that we have to prove: \(KB {\vdash}_{resolution} G \implies KB \models G\). To
put in English: the if resolution method can derive G from KB then G is satisfiable in every model of 
KB. We can instead prove that \(S = KB \cup \neg G\) is unsatisfiable if doing resolution on
S derives the null clause.\\

\paragraph{Lemma 1:} Let \(A^a \vee B^{b1}, C^c \vee B^{b2}\) be the input clauses of a resolution, and 
\(A^a \vee C^c\) is the result. If \(A^a \vee C^c\) is false under an interpretation I, then 
\(A^a \vee B^{b1}, C^c \vee B^{b2}\) is also false under I.\\
\indent Proof:
\begin{align*}
	&T((A^a \vee B^{b1}) \wedge (C^c \vee B^{b2}))\\
	&= T(A^a \wedge C^c) \vee T(A^a \wedge B^{b2}) \vee T(C^c \wedge B^{b1}) \vee T(B^{b1} \wedge 
	B^{b2})\\
	&\text{We have:}\\
	&W > T(A^a \vee C^c) \ge T(A^a \wedge C^c)\\
	&W > T(A^a \vee C^c) \ge T(A^a) \ge T(A^a \wedge B^{b2})\\
	&W > T(A^a \vee C^c) \ge T(C^c) \ge T(C^c \wedge B^{b1})\\
	&W > T(B^{b1} \wedge B^{b2}) \text{  (since b1 and b2 are in different sides w.r.t. W)}\\
	&\implies T((A^a \vee B^{b1}) \wedge (C^c \vee B^{b2})) < W \text{ (q.e.d)}
\end{align*}

\paragraph{Theorem:} If S \(\vdash_{resolution}\) NULL \(\implies\) S is unsatisfiable.\\
\indent Proof: Let S1 be the set of all clauses after doing resolution on S. We have \(null \in S1\), so
S1 is unsatisfiable. According to Lemma 1, S must also be unsatisfiable (q.e.d).\\
\subsection{Proof of Completeness}
\paragraph{} Proof of completeness means that we have to prove: \(KB \models G \implies KB {\vdash}_{resolution} G\). To put in English: the resolution method can derive G from KB if G is satisfiable in every model of 
KB. We can instead prove that if \(S = KB \cup \neg G\) is unsatisfiable,  doing resolution on
S derives the null clause.\\
\paragraph{} First, let's consider some definitions that will be
used in the proof:
\subsubsection{Definitions:}
\paragraph{}{\em Semantic tree:} Given a set of clauses S
containing n symbols \(A_1..A_n\), The semantic
tree if S is a n-depth complete binary tree, each level corresponding to a literal. Children branches
of a node is labeled \(A_i < W\) and \(A_i > W\). 
\(\implies\) The semantic tree represents every interpretation possible for S, with each branch from
root to a leaf corresponding to an interpretation. The trivial case of \(A_i = W\) is not considered.\\\\
\begin{figure}[h]
        \centering
\xytree{
	%&&\xynode[-2,-1,0,1,2]{S}\\
        &&&&\xynode{} \xyconnect{1,-2}"_{\(A_{1} < W\)}" \xyconnect{1,2}"^{\(A_{1} > W\)}"\\
        &&\xynode{} \xyconnect{1,-1}"_{\(A_{2} < W\)}" \xyconnect{1,1}"^{\(A_{2} > W\)}" 
	&&&& \xynode{} \xyconnect{1,-1}"_{\(A_{2} < W\)}" \xyconnect{1,1}"^{\(A_{2} > W\)}"\\ 
         &\xynode{} && \xynode{} && \xynode{} && \xynode{}\\ 
}
\caption{Semantic tree example}
\end{figure}
\\
\paragraph{}{\em Failure node:} A node is a failure node if there exists an interpretation corresponding to
the path from root to that node that S is false under that interpretation, and S is not false at 
any ancestor of that node.\\
\paragraph{}{\em Failure tree:} If every path from root to leaf contains a failure node, cut off the children
of those failure nodes, we get a failure tree.\\
\paragraph{}{\em Inference node:} A node in failure tree where both of its children are failure node.\\
\(\implies\) S is unsatisfiable if and only if it has a failure tree (1)\\
\(\implies\) There exists at least one inference node in a failure tree (2)\\
If a failure tree contains only one node, then it is false for the null interpretation.
Only null clause is false for null interpretation, so if S's failure tree contains only one node, S
must contain the null clause (3)\\
%
\subsubsection{Proof of completeness}
\paragraph{} Now we are going to prove that if \(S = KB \cup \neg G\) is 
unsatisfiable, resolution will derive the null clause from S. \\
According to (1), S has a failure tree. According to 2, S has at least one inference node.\\
\begin{figure}[H]
\xytree{
	%&&\xynode[-2,-1,0,1,2]{S}\\
        &&&&&&&\xynode{i} \xyconnect{1,-2}"_{\(A_{m} < W\)}" \xyconnect{1,2}"^{\(A_{m} > W\)}"\\
        &&&&&\xynode{j} &&&& \xynode{k} \\
}
\caption{An inference node i derived during inferencing by
resolution on S}
\end{figure}
\paragraph{}
Let i be an inference node with j and k are its children. Because S is false at j where \(A_m < W\),
there must be a false clause C1 in S in the form \(...\vee {A_{m}}^{a1}, a1 > W\) and every other 
literal in C1 must be false at i. Similarly, there exist a C2 in S that false at k, and it has the form 
\(\cdots\vee {A_{m}}^{a2}, a2 > W\), every other literal in C2 must also be false at i.
Doing resolution on C1 and C2, we get C which contains every false literal in C1, C2 but \(A_{m}\).
Then we have \(S \vee C\)'s failure tree is S's failure tree cutting off j and k.
\paragraph{} Repeat this process until there is only one node left. Now we have the transitive closure of resolution
on S, and this closure contain the null clause according to (3) (q.e.d).

\subsection{$\alpha-Resolution$ stragety in HA-based logic}
\subsubsection{A problem with resolution} 
\paragraph{} When reasoning with the resolution rule, there might
be several different derivation sequences that can prove the same
goal. However, these derivation sequences most likely don't have
the same confidence value. It is preferable to follow the one
with the highest confidence value, since this confidence value
expresses how {\em reliable} the proof using resolution is.
However, using resolution as it is will not guarantee that. To
illustrate this point, let's consider an example:

\paragraph{Example: }
Let $AX = \{X, G = {c^{+} = True, c^{-} =
False}, H = \{More, Very, Possibly, Less\}, \le\}$ \\ where
$H^{+} =
\{More, Very\}, More \le Very$, $H^{-} = \{Possibly, Less\},
Possibly \le Less$ be a Linear Symmetrical Hedge Algebra, with
Maxt and Mint as its maximal and minimal value. The relation matrix between its hedges is
defined as follows:
\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|}
      \hline
                  Affecting$\backslash$Affected & More & Very &
      Possibly & Less \\ \hline
                  More                        & +    & +    & -
      & -    \\ \hline
                  Very                        & +    & +    & -
      & +    \\ \hline
                  Possibly                    & -    & -    & -
      & -    \\ \hline
                  Less                        & -    & -    & -
      & -    \\ \hline
    \end{tabular}
    \caption {Relation matrix between hedges}
\end{table}
\paragraph{} Let Very, More, Possibly, Less be V, M, P, L for
short. Consider the following set of clauses:\\
\begin{enumerate}
  \item $A^{MFalse} \vee B^{False} \vee C^{VMTrue}$
  \item $B^{LTrue} \vee C^{PTrue}$
  \item $A^{PTrue}$
  \item $B^{VTrue}$
  \item $C^{VFalse}$
\end{enumerate}
\paragraph{} Let's perform resolution on this set of clauses. At
the beginning, every clause will be given maximal confidence
value.
\[
  \cfrac{ (B^{LTrue} \vee C^{PTrue},Maxt) (A^{MFalse} \vee B^{False} \vee
  C^{VMTrue}, MaxT)}
  {\qquad\qquad\qquad\qquad \cfrac{ (A^{MFalse} \vee C^{VMTrue}, LTrue) (A^{PTrue}, Maxt)}
    {\qquad\qquad\qquad\qquad \cfrac {(C^{VMTrue}, LTrue) (C^{VFalse}, Maxt)}
      {\qquad\qquad\qquad\qquad (NULL, LTrue)
        }
     }
    }
\]
\paragraph{} However, that is not the only derivation for this
set of clauses:
\[
  \cfrac{ (A^{PTrue},Maxt) (A^{MFalse} \vee B^{False} \vee
  C^{VMTrue}, MaxT)}
  {\qquad\qquad\qquad\qquad\cfrac{ (B^{False} \vee C^{VMTrue}, PTrue) (B^{VTrue}, Maxt)}
    {\qquad\qquad\qquad\qquad\cfrac {(C^{VMTrue}, PTrue) (C^{VFalse}, Maxt)}
      {\qquad\qquad\qquad\qquad(NULL, PTrue)
        }
     }
    }
\]
\paragraph{} This derivation however has the confidence value of
Possibly True, which is higher than Less True. This is in fact
the highest possible confidence value for this set of clauses,
but we are not guaranteed to arrive at it if we just use normal
resolution.
\paragraph{} Since different derivationa of the same conjunction of clauses may have different
confidence value, it is natural to study how to design a resolution 
procedure that will always follow the derivation best confidence. The section below present
$\alpha-Resolution$, a resolution strategy that can achieve
precisely that.
\subsubsection{Resolution with $\alpha-strategy$ derivation}
\paragraph{} 
We say that a set of clauses S is saturated iff for every fuzzy
linguistic resolution inference with premises in S, the
conclusion of this inference is a variant with smaller or equal
reliability of some clauses in S. That is for every fuzzy
linguistic resolution inference:\\
\[\indent \frac{(C1, \alpha1), (C2, \alpha2)}{(C,\alpha)}
\]
\indent there is some clause \((C',\alpha') \in \) S such that \(\alpha' \ge \alpha\).
\paragraph{} 
We introduce a resolution strategy, called $\alpha$-strategy, which guarantees that
the resolution proof of each clause has the maximal confidence
value. An $\alpha$-strategy
derivation is a sequence of the form $S_{0},\ldots,S_{i},\ldots$, where
\begin{itemize} 
	\item each Si is a set of clauses with confidence, and
	\item  \(S_{i+1}\) is obtained by adding the conclusion of a fuzzy 
	linguistic resolution inference with premises with
        maximal confidences 
	from Si , that is \(S_{i+1} = Si \cup \{(C, \alpha)\}\), 
	where (C, $\alpha$) is the conclusion of the fuzzy linguistic resolution inference  
	\(\frac{(C1 , \alpha1), (C2 , \alpha2)}	{(C, \alpha)}\)
	\\\\	
	$(C1 , \alpha1 ), (C2 , \alpha2 ) \in S_{i}$ and there are not any clauses 
	with reliability $(C1 , \alpha_{1}' ), (C2 , \alpha_{2}' ) \in S_{i}$ such that
			$\alpha_{1}' > \alpha_{1}$ and $\alpha_{2}' > \alpha_{2}$ , or

		\item $S_{i+1}$ is obtained by removing a variant with smaller 
			confidence, that is $S_{i+1} = S_{i} \setminus \{(C, \alpha)\}$ 
			where $(C, \alpha) \in S_{i}$ and there is some
			$(C, \alpha') \in S_{i}$ such that $\alpha < \alpha'$.
\end{itemize}
\paragraph{} 
\paragraph{The limit of a derivation $S_{0},\ldots,S_{i},\ldots$:} 
$S_{\infty} = \underset{i \ge 0}{\cup} \underset{j \ge i}{\cap}S_{j}$
\paragraph{} This obscure looking definition of the limit of a
derivation is just actually meant to say that, for a set to be the
limit of an $\alpha-strategy$ derivation sequence iff the result
of another $\alpha-strategy$ derivation step on it will not have
any new clause, and basically is just the same set. In other
words, the set is saturated
\paragraph{} The intuition behind $\alpha-Resolution$ is that if
at any derivation step, you try to only keep the version with highest
confidence of each clauses, when it eventually reaches
saturation, each of the clauses in the limit will have the
highest possible confidence it can get from the premise. The
next section will deal with the formalization for this intuition.
\subsubsection{Soundness and Completeness of $\alpha-Resolution$}
\paragraph{} The proof of completeness for $\alpha-Resolution$ is a direct
consequence of the proof of completeness for normal resolution
using proof tree, since $\alpha-Resolution$ still has the 
same proof tree with the same nodes like its normal resolution
equivalence.

\paragraph{} The following result establishes the soundness of
the $\alpha-Resolution$ procedure.
\paragraph{Theorem 2}
Let $S_{0},\ldots,S_{i},\ldots$ be a fuzzy linguistic resolution $\alpha$-strategy derivation.
Sn contains the empty clause iff S0 is unsatisfiable (for some n = 0, 1,\ldots).
\paragraph{Lemma 2} 
Consider the following resolution inferences:
\[ \frac{(A^{a} \vee B^{b1}, \alpha), (B^{b2} \vee C^{c}, \beta)} {(A^{a} \vee C^{c}, \gamma)}\]
\[\frac{(A^{a} \vee B^{b1}, \alpha), (B^{b2} \vee C^{c}, \beta')} {(A^{a} \vee C^{c}, \gamma')}\]
Then, $\beta' > \beta$ implies $\gamma' \ge \gamma$

\paragraph{Lemma 3} Let $S_{0},\ldots,S_{i},\ldots$ be a fuzzy linguistic 
resolution $\alpha$-strategy derivation, and $S_{\infty}$ be the the limit of the derivation.
Then $S_{\infty}$ is saturated.

\paragraph{Theorem 3} Let $S_{0},\ldots,S_{i},\ldots$ be a fuzzy linguistic 
resolution $\alpha$-strategy derivation, and $S_{\infty}$ be the the limit of the derivation. 
Then for each clause $(C, \alpha)$ in $S_{\infty}$ , there is not any other resolution proof 
of the clause $(C, \alpha')$ from $S_{0}$ such that $\alpha' > \alpha$.
\end{document}
